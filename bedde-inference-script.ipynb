{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a563e473",
   "metadata": {},
   "source": [
    "# BeDDE Dataset Inference \n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c2b41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:09.150320Z",
     "iopub.status.busy": "2024-07-17T22:27:09.149906Z",
     "iopub.status.idle": "2024-07-17T22:27:35.161061Z",
     "shell.execute_reply": "2024-07-17T22:27:35.159991Z"
    },
    "papermill": {
     "duration": 26.020146,
     "end_time": "2024-07-17T22:27:35.164142",
     "exception": false,
     "start_time": "2024-07-17T22:27:09.143996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch-enhance torchmetrics lpips -q\n",
    "import gc,os,cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lpips\n",
    "import pywt\n",
    "import shutil,time\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as tt \n",
    "from torch_enhance.losses import VGG as PerceptualLoss\n",
    "from torchmetrics.image import PeakSignalNoiseRatio,StructuralSimilarityIndexMeasure\n",
    "from joblib import Parallel,delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d28ef2",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca670e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.178768Z",
     "iopub.status.busy": "2024-07-17T22:27:35.177248Z",
     "iopub.status.idle": "2024-07-17T22:27:35.184170Z",
     "shell.execute_reply": "2024-07-17T22:27:35.183147Z"
    },
    "papermill": {
     "duration": 0.016795,
     "end_time": "2024-07-17T22:27:35.186979",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.170184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_transforms_rgb=tt.Compose([\n",
    "    tt.transforms.Resize((256,256),antialias=True),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=(0.6344,0.5955,0.5857),std=(0.1742,0.1798,0.1871))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e80454",
   "metadata": {
    "papermill": {
     "duration": 0.005293,
     "end_time": "2024-07-17T22:27:35.198029",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.192736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Initilaizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf08b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.211372Z",
     "iopub.status.busy": "2024-07-17T22:27:35.210287Z",
     "iopub.status.idle": "2024-07-17T22:27:35.257754Z",
     "shell.execute_reply": "2024-07-17T22:27:35.256655Z"
    },
    "papermill": {
     "duration": 0.056651,
     "end_time": "2024-07-17T22:27:35.260477",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.203826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PixelAttention(nn.Module):\n",
    "    def __init__(self,channel,reduct_ratio=8):\n",
    "        super(PixelAttention,self).__init__()\n",
    "        reduced_channel=max(1,channel//reduct_ratio)\n",
    "        self.pixel_attention=nn.Sequential(\n",
    "            nn.Conv2d(channel,channel//reduced_channel,kernel_size=1,padding=0,bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel//reduced_channel,1,kernel_size=1,padding=0,bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,feature):\n",
    "        x=self.pixel_attention(feature)\n",
    "        return x*feature\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self,input_channels,reduct_ratio=8):\n",
    "        super(ChannelAttention,self).__init__()\n",
    "        reduced_channel=max(1,input_channels//reduct_ratio)\n",
    "        self.avg_pooler=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fcn=nn.Sequential(\n",
    "            nn.Linear(input_channels,reduced_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduced_channel,input_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self,input_feature):\n",
    "        n,c,_,_=input_feature.size()\n",
    "        x=self.avg_pooler(input_feature).view(n,c)\n",
    "        x=F.sigmoid(self.fcn(x).view(n,c,1,1))\n",
    "        return input_feature*x\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self,dims,kernel_size=1):\n",
    "        super(AttentionBlock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(dims,dims,kernel_size,padding=(kernel_size//2),bias=True)\n",
    "        self.conv2=nn.Conv2d(dims,dims,kernel_size,padding=(kernel_size//2),bias=True)\n",
    "        self.ca=ChannelAttention(dims)\n",
    "        self.pa=PixelAttention(dims)\n",
    "    def forward(self,img):\n",
    "        feat=F.relu(self.conv1(img),inplace=True)\n",
    "        feat=feat+img\n",
    "        feat=F.relu(self.conv1(feat),inplace=True)\n",
    "        feat=self.ca(feat)\n",
    "        feat=self.pa(feat)\n",
    "        feat+=img\n",
    "        return feat\n",
    "class DWT_DehazingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DWT_DehazingNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.attn1=AttentionBlock(3)\n",
    "        self.conv3=nn.Conv2d(in_channels=9,out_channels=3,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv4=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=7,stride=1,padding=3)\n",
    "        self.attn2=AttentionBlock(3)\n",
    "        self.conv5=nn.Conv2d(in_channels=15,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv_dwt=nn.Conv2d(in_channels=12,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.b=1\n",
    "\n",
    "    def forward(self,x):\n",
    "        dwt_coeffs=pywt.dwt2(x.cpu(),wavelet='db4')\n",
    "        LL,(LH,HL,HH)=dwt_coeffs\n",
    "        dwt_out=torch.concat([torch.from_numpy(LL),torch.from_numpy(LH),torch.from_numpy(HL),torch.from_numpy(HH)],dim=1)\n",
    "        x1=F.relu(self.conv1(x))\n",
    "        dwt_out=tt.Resize((256,256))(dwt_out)\n",
    "        dwt_in=self.conv_dwt(dwt_out)\n",
    "        x2=F.relu(self.conv2(x1))\n",
    "        x2=self.attn1(x2)\n",
    "        cat1=torch.cat((x1,x2,dwt_in),1)\n",
    "        x3=F.relu(self.conv3(cat1))\n",
    "        cat2=torch.cat((x2,x3),1)\n",
    "        x4=F.relu(self.conv4(cat2))\n",
    "        x4=self.attn2(x4)\n",
    "        cat3=torch.cat((x1,x2,x3,x4,dwt_in),1)\n",
    "        k=F.relu(self.conv5(cat3))\n",
    "        output=k*x-k+self.b\n",
    "        return F.relu(output)\n",
    "class DehazingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DehazingNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.attn1=AttentionBlock(3)\n",
    "        self.conv3=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv4=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=7,stride=1,padding=3)\n",
    "        self.attn2=AttentionBlock(3)\n",
    "        self.conv5=nn.Conv2d(in_channels=12,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv_dwt=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.b=1\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=F.relu(self.conv1(x))\n",
    "        x2=F.relu(self.conv2(x1))\n",
    "        x2=self.attn1(x2)\n",
    "        cat1=torch.cat((x1,x2),1)\n",
    "        x3=F.relu(self.conv3(cat1))\n",
    "        cat2=torch.cat((x2,x3),1)\n",
    "        x4=F.relu(self.conv4(cat2))\n",
    "        x4=self.attn2(x4)\n",
    "        cat3=torch.cat((x1,x2,x3,x4),1)\n",
    "        k=F.relu(self.conv5(cat3))\n",
    "        output=k*x-k+self.b\n",
    "        return F.relu(output)\n",
    "class FinalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalCNN,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv3=nn.Conv2d(in_channels=32,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.relu3=nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.relu1(self.conv1(x))\n",
    "        x=self.relu2(self.conv2(x))\n",
    "        x=self.relu3(self.conv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e94956",
   "metadata": {},
   "source": [
    "## Loading Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff0635d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.270765Z",
     "iopub.status.busy": "2024-07-17T22:27:35.269565Z",
     "iopub.status.idle": "2024-07-17T22:27:35.359986Z",
     "shell.execute_reply": "2024-07-17T22:27:35.358715Z"
    },
    "papermill": {
     "duration": 0.098453,
     "end_time": "2024-07-17T22:27:35.362819",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.264366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwt_dehazenet_rgb=nn.DataParallel(DWT_DehazingNet())\n",
    "dehazenet_rgb=nn.DataParallel(DehazingNet())\n",
    "final_cnn=FinalCNN()\n",
    "\n",
    "\n",
    "dwt_dehazenet_rgb.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/dehazing-rgb-dwt-2l.pth',map_location=torch.device('cpu')))\n",
    "dehazenet_rgb.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/dehazenet-rgb-2l.pth',map_location=torch.device('cpu')))\n",
    "final_cnn.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/end_cnn.pth',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26d321",
   "metadata": {},
   "source": [
    "## Utility Functions for the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296afce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.372963Z",
     "iopub.status.busy": "2024-07-17T22:27:35.372414Z",
     "iopub.status.idle": "2024-07-17T22:27:35.398441Z",
     "shell.execute_reply": "2024-07-17T22:27:35.397029Z"
    },
    "papermill": {
     "duration": 0.034438,
     "end_time": "2024-07-17T22:27:35.401198",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.366760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_image_rgb(img_tensor,file_path):\n",
    "    if img_tensor.shape[0]!=3:\n",
    "        raise ValueError(\"Input tensor must have 3 channels only...\")\n",
    "    rgb_array=tensor_denormalize_rgb(img_tensor).permute(1,2,0).cpu().detach().numpy()\n",
    "    rgb_image=Image.fromarray((np.clip(rgb_array,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    rgb_image.save(file_path)\n",
    "\n",
    "def tensor_denormalize_rgb(out_tensor,mean=[0.4556,0.3837,0.3642],std=[0.2689,0.2691,0.2828]):\n",
    "    if len(out_tensor.shape)==3:\n",
    "        out_tensor=out_tensor.unsqueeze(0)\n",
    "    mean=torch.tensor(mean).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "    std=torch.tensor(std).unsqueeze(0).unsqueeze(2).unsqueeze(3)    \n",
    "    denorm_tensor=(out_tensor*std)+mean\n",
    "    return denorm_tensor.squeeze(0)\n",
    "def unsharp_mask(image,kernel_size=(5,5),sigma=0.4,amount=1.0,threshold=1):\n",
    "    blurred=cv2.GaussianBlur(image,kernel_size,sigma)\n",
    "    sharpened=float(amount+1)*image-float(amount)*blurred\n",
    "    sharpened=np.maximum(sharpened,np.zeros(sharpened.shape))\n",
    "    sharpened=np.minimum(sharpened,255*np.ones(sharpened.shape))\n",
    "    sharpened=sharpened.round().astype(np.uint8)\n",
    "    if threshold>0:\n",
    "        low_contrast_mask=np.absolute(image-blurred)<threshold\n",
    "        np.copyto(sharpened,image,where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "def clahe(image):\n",
    "    clahe=cv2.createCLAHE(clipLimit=1,tileGridSize=(2,2))\n",
    "    lab=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "    lab[:,:,0]=clahe.apply(lab[:,:,0])\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def enhance_image(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_sharpened=unsharp_mask(img)\n",
    "    image_clahe=clahe(image_sharpened)\n",
    "    image_tensor=tt.ToTensor()(image_clahe)   \n",
    "    return image_tensor\n",
    "def alpha_blending(image1, image2, alpha):\n",
    "    blended = cv2.addWeighted(image1, alpha, image2, 1 - alpha, 4)\n",
    "    return blended\n",
    "def image_addition(coeff,img_path1,img_path2):\n",
    "    img1=cv2.cvtColor(cv2.imread(img_path1),cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.cvtColor(cv2.imread(img_path2),cv2.COLOR_BGR2RGB)\n",
    "    img_f=tt.ToTensor()(alpha_blending(img1,img2,coeff))    \n",
    "    return img_f\n",
    "def save_image_final(img_tensor,file_path):\n",
    "    if img_tensor.shape[0]!=3:\n",
    "        raise ValueError(\"Input tensor must have 3 channels only...\")\n",
    "    rgb_array=img_tensor.permute(1,2,0).cpu().detach().numpy()\n",
    "    rgb_image=Image.fromarray((np.clip(rgb_array,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    rgb_image.save(file_path)\n",
    "def enhance_image_merged(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.fastNlMeansDenoisingColored(img,None,10,10,3,21)\n",
    "    image_sharpened=unsharp_mask(img2)\n",
    "    image_clahe=clahe(image_sharpened)\n",
    "    image_tensor=tt.ToTensor()(image_clahe)   \n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7967da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.411302Z",
     "iopub.status.busy": "2024-07-17T22:27:35.410930Z",
     "iopub.status.idle": "2024-07-17T22:27:35.429981Z",
     "shell.execute_reply": "2024-07-17T22:27:35.428277Z"
    },
    "papermill": {
     "duration": 0.027992,
     "end_time": "2024-07-17T22:27:35.433189",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.405197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "psnr_fn,ssim_fn=PeakSignalNoiseRatio(),StructuralSimilarityIndexMeasure()\n",
    "def metrics_calculator(out_path,clear_path):\n",
    "    out_tensor=tt.ToTensor()(cv2.imread(out_path))\n",
    "    clear_tensor=tt.ToTensor()(cv2.resize(cv2.imread(clear_path),(256,256)))\n",
    "    return psnr_fn(out_tensor,clear_tensor),ssim_fn(out_tensor.unsqueeze(0),clear_tensor.unsqueeze(0))\n",
    "def averager(li):\n",
    "    return sum(li)/len(li)\n",
    "\n",
    "def model1_image_pass(img_tensor,folder_name,i,clear_path):\n",
    "    model_output1=dwt_dehazenet_rgb(img_tensor.unsqueeze(0)).cpu()\n",
    "    save_image_rgb(model_output1.squeeze(),f'/kaggle/working/{folder_name}/output_image_{i}_1.png')\n",
    "    psnr1_1,ssim1_1=metrics_calculator(f'/kaggle/working/{folder_name}/output_image_{i}_1.png',clear_path)\n",
    "    proc_out_tensor1=enhance_image(f'/kaggle/working/{folder_name}/output_image_{i}_1.png')\n",
    "    proc_arr1=proc_out_tensor1.permute(1,2,0).cpu().detach().numpy()\n",
    "    proc_image1=Image.fromarray((np.clip(proc_arr1,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    proc_image1.save(f'/kaggle/working/{folder_name}/processed_image_{i}_1.png')\n",
    "    psnr2_1,ssim_2_1=metrics_calculator(f'/kaggle/working/{folder_name}/processed_image_{i}_1.png',clear_path)\n",
    "    return proc_arr1,psnr1_1,ssim1_1,psnr2_1,ssim_2_1\n",
    "    \n",
    "    \n",
    "def model2_image_pass(img_tensor,folder_name,i,clear_path):\n",
    "    model_output2=dehazenet_rgb(img_tensor.unsqueeze(0)).cpu()\n",
    "    save_image_rgb(model_output2.squeeze(),f'/kaggle/working/{folder_name}/output_image_{i}_2.png')\n",
    "    psnr1_2,ssim1_2=metrics_calculator(f'/kaggle/working/{folder_name}/output_image_{i}_2.png',clear_path)\n",
    "    proc_out_tensor2=enhance_image(f'/kaggle/working/{folder_name}/output_image_{i}_2.png')\n",
    "    proc_arr2=proc_out_tensor2.permute(1,2,0).cpu().detach().numpy()\n",
    "    proc_image2=Image.fromarray((np.clip(proc_arr2,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    proc_image2.save(f'/kaggle/working/{folder_name}/processed_image_{i}_2.png')\n",
    "    psnr2_2,ssim_2_2=metrics_calculator(f'/kaggle/working/{folder_name}/processed_image_{i}_2.png',clear_path)\n",
    "    psnr,ssim=metrics_calculator(f'/kaggle/working/{folder_name}/processed_image_{i}_2.png',clear_path)\n",
    "    return proc_arr2,psnr1_2,ssim1_2,psnr2_2,ssim_2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9b4c6",
   "metadata": {},
   "source": [
    "## Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82659626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:35.442972Z",
     "iopub.status.busy": "2024-07-17T22:27:35.442579Z",
     "iopub.status.idle": "2024-07-17T22:27:42.795288Z",
     "shell.execute_reply": "2024-07-17T22:27:42.793948Z"
    },
    "papermill": {
     "duration": 7.360718,
     "end_time": "2024-07-17T22:27:42.798010",
     "exception": false,
     "start_time": "2024-07-17T22:27:35.437292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def model_run_parallel(haze_img_path,clear_img_path,coeff=0.6,i=0,folder_name='Inference_Results'):\n",
    "    os.makedirs(f'/kaggle/working/{folder_name}',exist_ok=True)\n",
    "    dwt_dehazenet_rgb.eval()\n",
    "    dwt_dehazenet_rgb.eval()\n",
    "    start_time=time.time()\n",
    "    haze_img_tensor=cv2.cvtColor(cv2.imread(haze_img_path),cv2.COLOR_BGR2RGB)\n",
    "    haze_img_tensor=Image.open(haze_img_path)\n",
    "    img_tensor=input_transforms_rgb(haze_img_tensor).cpu()\n",
    "    out1,out2=Parallel(n_jobs=2)(delayed(func)(img_tensor,folder_name,i,clear_img_path) for func in [model1_image_pass,model2_image_pass])\n",
    "    #out1,out2=model1_image_pass(img_tensor,folder_name,i,clear_img_path),model2_image_pass(img_tensor,folder_name,i,clear_img_path)\n",
    "    psnr_mod11,ssim_mod11,psnr_mod21,ssim_mod21,psnr_mod12,ssim_mod12,psnr_mod22,ssim_mod22=out1[1],out1[2],out1[3],out1[4],out2[1],out2[2],out2[3],out2[4]\n",
    "    blended_image=image_addition(coeff,f'/kaggle/working/{folder_name}/processed_image_{i}_2.png',\n",
    "                                 f'/kaggle/working/{folder_name}/processed_image_{i}_1.png')\n",
    "    save_image_final(blended_image.squeeze(),f'/kaggle/working/{folder_name}/merged_image_{i}.png')\n",
    "    psnr_blend,ssim_blend=metrics_calculator(f'/kaggle/working/{folder_name}/merged_image_{i}.png',clear_img_path)\n",
    "    \n",
    "    proc_blended=enhance_image_merged(f'/kaggle/working/{folder_name}/merged_image_{i}.png')\n",
    "    save_image_final(blended_image.squeeze(),f'/kaggle/working/{folder_name}/proc_merged_image_{i}.png')\n",
    "    psnr_procblend,ssim_procblend=metrics_calculator(f'/kaggle/working/{folder_name}/proc_merged_image_{i}.png',clear_img_path)\n",
    "    \n",
    "    cnn_processed=final_cnn(tt.ToTensor()(cv2.cvtColor(cv2.imread(f'/kaggle/working/{folder_name}/proc_merged_image_{i}.png'),\n",
    "                                                       cv2.COLOR_BGR2RGB)))\n",
    "    save_image_final(cnn_processed.squeeze(),f'/kaggle/working/{folder_name}/cnn_processed_image_{i}.png')\n",
    "    psnr_cnn,ssim_cnn=metrics_calculator(f'/kaggle/working/{folder_name}/cnn_processed_image_{i}.png',clear_img_path)\n",
    "    return psnr_mod11,ssim_mod11,psnr_mod21,ssim_mod21,psnr_mod12,ssim_mod12,psnr_mod22,ssim_mod22,psnr_blend,ssim_blend,psnr_procblend,ssim_procblend,psnr_cnn,ssim_cnn\n",
    "\n",
    "out=model_run_parallel('/kaggle/input/dehazing-dataset-thesis/BeDDE/BeDDE/beijing/fog/beijing_1.png','/kaggle/input/dehazing-dataset-thesis/BeDDE/BeDDE/beijing/gt/beijing_clear.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e406c",
   "metadata": {},
   "source": [
    "## Preparing BeDDE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d59139a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:42.808909Z",
     "iopub.status.busy": "2024-07-17T22:27:42.807777Z",
     "iopub.status.idle": "2024-07-17T22:27:42.967341Z",
     "shell.execute_reply": "2024-07-17T22:27:42.966254Z"
    },
    "papermill": {
     "duration": 0.167564,
     "end_time": "2024-07-17T22:27:42.969748",
     "exception": false,
     "start_time": "2024-07-17T22:27:42.802184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GT</th>\n",
       "      <th>Hazy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "      <td>/kaggle/input/dehazing-dataset-thesis/BeDDE/Be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  GT  \\\n",
       "0  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...   \n",
       "1  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...   \n",
       "2  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...   \n",
       "3  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...   \n",
       "4  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...   \n",
       "\n",
       "                                                Hazy  \n",
       "0  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...  \n",
       "1  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...  \n",
       "2  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...  \n",
       "3  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...  \n",
       "4  /kaggle/input/dehazing-dataset-thesis/BeDDE/Be...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazy_images=list(glob('/kaggle/input/dehazing-dataset-thesis/BeDDE/BeDDE/*/fog/*'))\n",
    "hazy_images.sort()\n",
    "clear_images=list(map(lambda x:x.split('_')[0]+'_clear.png',hazy_images))\n",
    "clear_images=list(map(lambda x:'/'.join(x.split('/')[:7])+'/gt/'+x.split('/')[-1],clear_images))\n",
    "clear_images.sort()\n",
    "tabular_data_bedde=pd.DataFrame({'GT':clear_images,\n",
    "                                     'Hazy':hazy_images})\n",
    "tabular_data_bedde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5703e9c",
   "metadata": {},
   "source": [
    "## Procuring Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ccde87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T22:27:42.980223Z",
     "iopub.status.busy": "2024-07-17T22:27:42.979377Z",
     "iopub.status.idle": "2024-07-17T23:09:58.983285Z",
     "shell.execute_reply": "2024-07-17T23:09:58.981982Z"
    },
    "papermill": {
     "duration": 2536.01683,
     "end_time": "2024-07-17T23:09:58.990783",
     "exception": false,
     "start_time": "2024-07-17T22:27:42.973953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Coefficient 0.1 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3676479000311632\n",
      "Average metrics at DWT Dehazernet: 13.424005508422852 and 0.6109381318092346\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504715919494629 and 0.6310338377952576\n",
      "Average metrics at Dehazernet: 13.484880447387695 and 0.6228863000869751\n",
      "Average metrics at Postprocessing Dehazernet: 13.704506874084473 and 0.649851381778717\n",
      "Average metrics at Blending: 13.674162864685059 and 0.6358555555343628\n",
      "Average metrics at Postprocessing Blending: 13.674162864685059 and 0.6358555555343628\n",
      "Average metrics at Enhancer CNN: 10.104741096496582 and 0.548007071018219\n",
      "------------- Coefficient 0.2 -----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed....\n",
      "Average workflow processing time: 1.3625887798575254\n",
      "Average metrics at DWT Dehazernet: 13.424007415771484 and 0.6109377145767212\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.50472354888916 and 0.6310337781906128\n",
      "Average metrics at Dehazernet: 13.48487377166748 and 0.6228865385055542\n",
      "Average metrics at Postprocessing Dehazernet: 13.704508781433105 and 0.6498512625694275\n",
      "Average metrics at Blending: 13.688080787658691 and 0.6376113891601562\n",
      "Average metrics at Postprocessing Blending: 13.688080787658691 and 0.6376113891601562\n",
      "Average metrics at Enhancer CNN: 10.113666534423828 and 0.5496776700019836\n",
      "------------- Coefficient 0.3 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3592651772957582\n",
      "Average metrics at DWT Dehazernet: 13.424004554748535 and 0.6109381914138794\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504729270935059 and 0.6310337781906128\n",
      "Average metrics at Dehazernet: 13.484878540039062 and 0.6228864192962646\n",
      "Average metrics at Postprocessing Dehazernet: 13.704513549804688 and 0.649851381778717\n",
      "Average metrics at Blending: 13.70071792602539 and 0.6391616463661194\n",
      "Average metrics at Postprocessing Blending: 13.70071792602539 and 0.6391616463661194\n",
      "Average metrics at Enhancer CNN: 10.121769905090332 and 0.5511589050292969\n",
      "------------- Coefficient 0.4 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3594552433261504\n",
      "Average metrics at DWT Dehazernet: 13.424005508422852 and 0.6109384298324585\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.50472354888916 and 0.6310337781906128\n",
      "Average metrics at Dehazernet: 13.484871864318848 and 0.6228863596916199\n",
      "Average metrics at Postprocessing Dehazernet: 13.704517364501953 and 0.6498514413833618\n",
      "Average metrics at Blending: 13.712173461914062 and 0.6405741572380066\n",
      "Average metrics at Postprocessing Blending: 13.712173461914062 and 0.6405741572380066\n",
      "Average metrics at Enhancer CNN: 10.129176139831543 and 0.5525267124176025\n",
      "------------- Coefficient 0.5 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3587691815999838\n",
      "Average metrics at DWT Dehazernet: 13.424005508422852 and 0.6109387278556824\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504719734191895 and 0.631033718585968\n",
      "Average metrics at Dehazernet: 13.484867095947266 and 0.6228860020637512\n",
      "Average metrics at Postprocessing Dehazernet: 13.704519271850586 and 0.6498516201972961\n",
      "Average metrics at Blending: 13.723209381103516 and 0.6417518258094788\n",
      "Average metrics at Postprocessing Blending: 13.723209381103516 and 0.6417518258094788\n",
      "Average metrics at Enhancer CNN: 10.136723518371582 and 0.5537930130958557\n",
      "------------- Coefficient 0.6 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3576955168675153\n",
      "Average metrics at DWT Dehazernet: 13.424006462097168 and 0.6109389662742615\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504714965820312 and 0.631033718585968\n",
      "Average metrics at Dehazernet: 13.48486614227295 and 0.6228857636451721\n",
      "Average metrics at Postprocessing Dehazernet: 13.704519271850586 and 0.6498517990112305\n",
      "Average metrics at Blending: 13.73381519317627 and 0.6429044008255005\n",
      "Average metrics at Postprocessing Blending: 13.73381519317627 and 0.6429044008255005\n",
      "Average metrics at Enhancer CNN: 10.144295692443848 and 0.554996907711029\n",
      "------------- Coefficient 0.7 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3575054249920688\n",
      "Average metrics at DWT Dehazernet: 13.424012184143066 and 0.6109391450881958\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504712104797363 and 0.631033718585968\n",
      "Average metrics at Dehazernet: 13.484872817993164 and 0.6228855848312378\n",
      "Average metrics at Postprocessing Dehazernet: 13.704514503479004 and 0.6498518586158752\n",
      "Average metrics at Blending: 13.74365520477295 and 0.6439138054847717\n",
      "Average metrics at Postprocessing Blending: 13.74365520477295 and 0.6439138054847717\n",
      "Average metrics at Enhancer CNN: 10.151718139648438 and 0.556110143661499\n",
      "------------- Coefficient 0.8 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3561173463956668\n",
      "Average metrics at DWT Dehazernet: 13.424015998840332 and 0.6109392642974854\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.50471019744873 and 0.6310338973999023\n",
      "Average metrics at Dehazernet: 13.484877586364746 and 0.6228855848312378\n",
      "Average metrics at Postprocessing Dehazernet: 13.704511642456055 and 0.6498517990112305\n",
      "Average metrics at Blending: 13.7530517578125 and 0.6447588205337524\n",
      "Average metrics at Postprocessing Blending: 13.7530517578125 and 0.6447588205337524\n",
      "Average metrics at Enhancer CNN: 10.15933895111084 and 0.5571197271347046\n",
      "------------- Coefficient 0.9 -----------------------\n",
      "Processed....\n",
      "Average workflow processing time: 1.3544341287551782\n",
      "Average metrics at DWT Dehazernet: 13.424018859863281 and 0.6109392046928406\n",
      "Average metrics at Postprocessing DWT Dehazernet: 13.504708290100098 and 0.6310340166091919\n",
      "Average metrics at Dehazernet: 13.484881401062012 and 0.6228861212730408\n",
      "Average metrics at Postprocessing Dehazernet: 13.704508781433105 and 0.6498513221740723\n",
      "Average metrics at Blending: 13.762162208557129 and 0.6454612612724304\n",
      "Average metrics at Postprocessing Blending: 13.762162208557129 and 0.6454612612724304\n",
      "Average metrics at Enhancer CNN: 10.167282104492188 and 0.5580360293388367\n"
     ]
    }
   ],
   "source": [
    "time_data,psnr_mod11,ssim_mod11,psnr_mod21,ssim_mod21,psnr_mod12,ssim_mod12,psnr_mod22,ssim_mod22,psnr_blend,ssim_blend,psnr_procblend,ssim_procblend,psnr_cnn,ssim_cnn=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "for x in range(1,10):\n",
    "    print(f'------------- Coefficient {x/10} -----------------------')\n",
    "    for idx,(clear,hazy) in enumerate(tabular_data_bedde.values):\n",
    "        coeff=x/10\n",
    "        start_time=time.time()\n",
    "        outputs=model_run_parallel(hazy,clear,coeff,idx)\n",
    "        time_data.append(time.time()-start_time)\n",
    "        psnr_mod11.append(outputs[0])\n",
    "        ssim_mod11.append(outputs[1])\n",
    "        psnr_mod21.append(outputs[2])\n",
    "        ssim_mod21.append(outputs[3])\n",
    "        psnr_mod12.append(outputs[4])\n",
    "        ssim_mod12.append(outputs[5])\n",
    "        psnr_mod22.append(outputs[6])\n",
    "        ssim_mod22.append(outputs[7])\n",
    "        psnr_blend.append(outputs[8])\n",
    "        ssim_blend.append(outputs[9])\n",
    "        psnr_procblend.append(outputs[10])\n",
    "        ssim_procblend.append(outputs[11])\n",
    "        psnr_cnn.append(outputs[12])\n",
    "        ssim_cnn.append(outputs[13])\n",
    "\n",
    "    print('Processed....')\n",
    "    print(f\"Average workflow processing time: {averager(time_data)}\")\n",
    "    print(f\"Average metrics at DWT Dehazernet: {averager(psnr_mod11)} and {averager(ssim_mod11)}\")\n",
    "    print(f\"Average metrics at Postprocessing DWT Dehazernet: {averager(psnr_mod21)} and {averager(ssim_mod21)}\")\n",
    "    print(f\"Average metrics at Dehazernet: {averager(psnr_mod12)} and {averager(ssim_mod12)}\")\n",
    "    print(f\"Average metrics at Postprocessing Dehazernet: {averager(psnr_mod22)} and {averager(ssim_mod22)}\")\n",
    "    print(f\"Average metrics at Blending: {averager(psnr_blend)} and {averager(ssim_blend)}\")\n",
    "    print(f\"Average metrics at Postprocessing Blending: {averager(psnr_procblend)} and {averager(ssim_procblend)}\")\n",
    "    print(f\"Average metrics at Enhancer CNN: {averager(psnr_cnn)} and {averager(ssim_cnn)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5101434,
     "sourceId": 8729607,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5239863,
     "sourceId": 8857586,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2575.909967,
   "end_time": "2024-07-17T23:10:01.633504",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-17T22:27:05.723537",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
