{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b8e417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:09:30.644987Z",
     "iopub.status.busy": "2024-07-09T16:09:30.644573Z",
     "iopub.status.idle": "2024-07-09T16:09:48.147554Z",
     "shell.execute_reply": "2024-07-09T16:09:48.146166Z"
    },
    "papermill": {
     "duration": 17.513635,
     "end_time": "2024-07-09T16:09:48.150573",
     "exception": false,
     "start_time": "2024-07-09T16:09:30.636938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch-enhance torchmetrics lpips -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d7afb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:09:48.164258Z",
     "iopub.status.busy": "2024-07-09T16:09:48.163820Z",
     "iopub.status.idle": "2024-07-09T16:09:59.934699Z",
     "shell.execute_reply": "2024-07-09T16:09:59.932953Z"
    },
    "papermill": {
     "duration": 11.781258,
     "end_time": "2024-07-09T16:09:59.937973",
     "exception": false,
     "start_time": "2024-07-09T16:09:48.156715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc,os,cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lpips\n",
    "import pywt\n",
    "import shutil,time\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as tt \n",
    "from torch_enhance.losses import VGG as PerceptualLoss\n",
    "from torchmetrics.image import PeakSignalNoiseRatio,StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b119f4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:09:59.952561Z",
     "iopub.status.busy": "2024-07-09T16:09:59.951550Z",
     "iopub.status.idle": "2024-07-09T16:09:59.978111Z",
     "shell.execute_reply": "2024-07-09T16:09:59.976706Z"
    },
    "papermill": {
     "duration": 0.037625,
     "end_time": "2024-07-09T16:09:59.981351",
     "exception": false,
     "start_time": "2024-07-09T16:09:59.943726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv('/kaggle/input/dehazing-dataset-thesis/dehazing_dataset_sample_test.csv')\n",
    "test_data=pd.read_csv('/kaggle/input/dehazing-dataset-thesis/dehazing_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3111c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:09:59.994614Z",
     "iopub.status.busy": "2024-07-09T16:09:59.994150Z",
     "iopub.status.idle": "2024-07-09T16:10:00.003395Z",
     "shell.execute_reply": "2024-07-09T16:10:00.002048Z"
    },
    "papermill": {
     "duration": 0.019071,
     "end_time": "2024-07-09T16:10:00.006263",
     "exception": false,
     "start_time": "2024-07-09T16:09:59.987192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DehazingDataset_RGB(Dataset):\n",
    "    def __init__(self,dataset,in_transforms=None,out_transforms=None):\n",
    "        self.dataset=dataset\n",
    "        self.in_transforms=in_transforms\n",
    "        self.out_transforms=out_transforms\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self,idx):\n",
    "        hazy_img_path=self.dataset.iloc[idx,1]\n",
    "        clear_img_path=self.dataset.iloc[idx,0]\n",
    "        if self.in_transforms:\n",
    "            hazy_img=self.in_transforms(Image.open(str(hazy_img_path)))\n",
    "        if self.out_transforms:\n",
    "            clear_img=self.out_transforms(Image.open(str(clear_img_path)))\n",
    "        return {'hazy':hazy_img,\n",
    "               'gt':clear_img}\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca252231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.021196Z",
     "iopub.status.busy": "2024-07-09T16:10:00.019738Z",
     "iopub.status.idle": "2024-07-09T16:10:00.029576Z",
     "shell.execute_reply": "2024-07-09T16:10:00.028107Z"
    },
    "papermill": {
     "duration": 0.020319,
     "end_time": "2024-07-09T16:10:00.032366",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.012047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_transforms_rgb=tt.Compose([\n",
    "    tt.transforms.Resize((256,256)),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=(0.6344,0.5955,0.5857),std=(0.1742,0.1798,0.1871))\n",
    "])\n",
    "output_transforms_rgb=tt.Compose([\n",
    "    tt.transforms.Resize((256,256)),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=(0.4556,0.3837,0.3642),std=(0.2689,0.2691,0.2828))\n",
    "])\n",
    "\n",
    "test_dataset_rgb=DehazingDataset_RGB(test_data,input_transforms_rgb,output_transforms_rgb)\n",
    "test_sample_dataset_rgb=DehazingDataset_RGB(test_sample,input_transforms_rgb,output_transforms_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f93c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.046232Z",
     "iopub.status.busy": "2024-07-09T16:10:00.045308Z",
     "iopub.status.idle": "2024-07-09T16:10:00.051979Z",
     "shell.execute_reply": "2024-07-09T16:10:00.050709Z"
    },
    "papermill": {
     "duration": 0.016782,
     "end_time": "2024-07-09T16:10:00.054800",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.038018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sample_loader_rgb=DataLoader(test_sample_dataset_rgb,batch_size=1)\n",
    "test_loader_rgb=DataLoader(test_dataset_rgb,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff0654",
   "metadata": {
    "papermill": {
     "duration": 0.005298,
     "end_time": "2024-07-09T16:10:00.065954",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.060656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Initilaizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d98b576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.079292Z",
     "iopub.status.busy": "2024-07-09T16:10:00.078891Z",
     "iopub.status.idle": "2024-07-09T16:10:00.123818Z",
     "shell.execute_reply": "2024-07-09T16:10:00.122477Z"
    },
    "papermill": {
     "duration": 0.055519,
     "end_time": "2024-07-09T16:10:00.126969",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.071450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PixelAttention(nn.Module):\n",
    "    def __init__(self,channel,reduct_ratio=8):\n",
    "        super(PixelAttention,self).__init__()\n",
    "        reduced_channel=max(1,channel//reduct_ratio)\n",
    "        self.pixel_attention=nn.Sequential(\n",
    "            nn.Conv2d(channel,channel//reduced_channel,kernel_size=1,padding=0,bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel//reduced_channel,1,kernel_size=1,padding=0,bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,feature):\n",
    "        x=self.pixel_attention(feature)\n",
    "        return x*feature\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self,input_channels,reduct_ratio=8):\n",
    "        super(ChannelAttention,self).__init__()\n",
    "        reduced_channel=max(1,input_channels//reduct_ratio)\n",
    "        self.avg_pooler=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fcn=nn.Sequential(\n",
    "            nn.Linear(input_channels,reduced_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(reduced_channel,input_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self,input_feature):\n",
    "        n,c,_,_=input_feature.size()\n",
    "        x=self.avg_pooler(input_feature).view(n,c)\n",
    "        x=F.sigmoid(self.fcn(x).view(n,c,1,1))\n",
    "        return input_feature*x\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self,dims,kernel_size=1):\n",
    "        super(AttentionBlock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(dims,dims,kernel_size,padding=(kernel_size//2),bias=True)\n",
    "        self.conv2=nn.Conv2d(dims,dims,kernel_size,padding=(kernel_size//2),bias=True)\n",
    "        self.ca=ChannelAttention(dims)\n",
    "        self.pa=PixelAttention(dims)\n",
    "    def forward(self,img):\n",
    "        feat=F.relu(self.conv1(img),inplace=True)\n",
    "        feat=feat+img\n",
    "        feat=F.relu(self.conv1(feat),inplace=True)\n",
    "        feat=self.ca(feat)\n",
    "        feat=self.pa(feat)\n",
    "        feat+=img\n",
    "        return feat\n",
    "class DWT_DehazingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DWT_DehazingNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.attn1=AttentionBlock(3)\n",
    "        self.conv3=nn.Conv2d(in_channels=9,out_channels=3,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv4=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=7,stride=1,padding=3)\n",
    "        self.attn2=AttentionBlock(3)\n",
    "        self.conv5=nn.Conv2d(in_channels=15,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv_dwt=nn.Conv2d(in_channels=12,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.b=1\n",
    "\n",
    "    def forward(self,x):\n",
    "        dwt_coeffs=pywt.dwt2(x.cpu(),wavelet='db4')\n",
    "        LL,(LH,HL,HH)=dwt_coeffs\n",
    "        dwt_out=torch.concat([torch.from_numpy(LL),torch.from_numpy(LH),torch.from_numpy(HL),torch.from_numpy(HH)],dim=1)\n",
    "        x1=F.relu(self.conv1(x))\n",
    "        dwt_out=tt.Resize((256,256))(dwt_out)\n",
    "        dwt_in=self.conv_dwt(dwt_out)\n",
    "        x2=F.relu(self.conv2(x1))\n",
    "        x2=self.attn1(x2)\n",
    "        cat1=torch.cat((x1,x2,dwt_in),1)\n",
    "        x3=F.relu(self.conv3(cat1))\n",
    "        cat2=torch.cat((x2,x3),1)\n",
    "        x4=F.relu(self.conv4(cat2))\n",
    "        x4=self.attn2(x4)\n",
    "        cat3=torch.cat((x1,x2,x3,x4,dwt_in),1)\n",
    "        k=F.relu(self.conv5(cat3))\n",
    "\n",
    "        if k.size() != x.size():\n",
    "            raise Exception(\"Different transmission map and hazy image size\")\n",
    "\n",
    "        output=k*x-k+self.b\n",
    "        return F.relu(output)\n",
    "class DehazingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DehazingNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2=nn.Conv2d(in_channels=3,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.attn1=AttentionBlock(3)\n",
    "        self.conv3=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv4=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=7,stride=1,padding=3)\n",
    "        self.attn2=AttentionBlock(3)\n",
    "        self.conv5=nn.Conv2d(in_channels=12,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv_dwt=nn.Conv2d(in_channels=6,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.b=1\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=F.relu(self.conv1(x))\n",
    "        x2=F.relu(self.conv2(x1))\n",
    "        x2=self.attn1(x2)\n",
    "        cat1=torch.cat((x1,x2),1)\n",
    "        x3=F.relu(self.conv3(cat1))\n",
    "        cat2=torch.cat((x2,x3),1)\n",
    "        x4=F.relu(self.conv4(cat2))\n",
    "        x4=self.attn2(x4)\n",
    "        cat3=torch.cat((x1,x2,x3,x4),1)\n",
    "        k=F.relu(self.conv5(cat3))\n",
    "\n",
    "        if k.size() != x.size():\n",
    "            raise Exception(\"Different transmission map and hazy image size\")\n",
    "\n",
    "        output=k*x-k+self.b\n",
    "        return F.relu(output)\n",
    "class FinalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalCNN,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv3=nn.Conv2d(in_channels=32,out_channels=3,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.relu3=nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.relu1(self.conv1(x))\n",
    "        x=self.relu2(self.conv2(x))\n",
    "        x=self.relu3(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3981365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.140229Z",
     "iopub.status.busy": "2024-07-09T16:10:00.139774Z",
     "iopub.status.idle": "2024-07-09T16:10:00.219115Z",
     "shell.execute_reply": "2024-07-09T16:10:00.218029Z"
    },
    "papermill": {
     "duration": 0.089,
     "end_time": "2024-07-09T16:10:00.221780",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.132780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwt_dehazenet_rgb=nn.DataParallel(DWT_DehazingNet())\n",
    "dehazenet_rgb=nn.DataParallel(DehazingNet())\n",
    "final_cnn=FinalCNN()\n",
    "\n",
    "\n",
    "dwt_dehazenet_rgb.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/dehazing-rgb-dwt-2l.pth',map_location=torch.device('cpu')))\n",
    "dehazenet_rgb.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/dehazenet-rgb-2l.pth',map_location=torch.device('cpu')))\n",
    "final_cnn.load_state_dict(torch.load(r'/kaggle/input/dehazing-models-ct5129/end_cnn.pth',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9b81f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.235055Z",
     "iopub.status.busy": "2024-07-09T16:10:00.234651Z",
     "iopub.status.idle": "2024-07-09T16:10:00.246953Z",
     "shell.execute_reply": "2024-07-09T16:10:00.245603Z"
    },
    "papermill": {
     "duration": 0.022397,
     "end_time": "2024-07-09T16:10:00.249885",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.227488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_image_rgb(img_tensor,file_path):\n",
    "    if img_tensor.shape[0]!=3:\n",
    "        raise ValueError(\"Input tensor must have 3 channels only...\")\n",
    "    rgb_array=tensor_denormalize_rgb(img_tensor).permute(1,2,0).cpu().detach().numpy()\n",
    "    rgb_image=Image.fromarray((np.clip(rgb_array,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    rgb_image.save(file_path)\n",
    "\n",
    "def tensor_denormalize_rgb(out_tensor,mean=[0.4556,0.3837,0.3642],std=[0.2689,0.2691,0.2828]):\n",
    "    if len(out_tensor.shape)==3:\n",
    "        out_tensor=out_tensor.unsqueeze(0)\n",
    "    mean=torch.tensor(mean).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "    std=torch.tensor(std).unsqueeze(0).unsqueeze(2).unsqueeze(3)    \n",
    "    denorm_tensor=(out_tensor*std)+mean\n",
    "    return denorm_tensor.squeeze(0)\n",
    "\n",
    "def metrics_calculator(out_path,clear_path):\n",
    "    out_tensor=tt.ToTensor()(cv2.imread(out_path))\n",
    "    clear_tensor=tt.ToTensor()(cv2.imread(clear_path))\n",
    "    return psnr_fn(out_tensor,clear_tensor),ssim_fn(out_tensor.unsqueeze(0),clear_tensor.unsqueeze(0))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7854aafd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.263245Z",
     "iopub.status.busy": "2024-07-09T16:10:00.262829Z",
     "iopub.status.idle": "2024-07-09T16:10:00.281718Z",
     "shell.execute_reply": "2024-07-09T16:10:00.280443Z"
    },
    "papermill": {
     "duration": 0.028811,
     "end_time": "2024-07-09T16:10:00.284478",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.255667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unsharp_mask(image,kernel_size=(5,5),sigma=0.4,amount=1.0,threshold=1):\n",
    "    blurred=cv2.GaussianBlur(image,kernel_size,sigma)\n",
    "    sharpened=float(amount+1)*image-float(amount)*blurred\n",
    "    sharpened=np.maximum(sharpened,np.zeros(sharpened.shape))\n",
    "    sharpened=np.minimum(sharpened,255*np.ones(sharpened.shape))\n",
    "    sharpened=sharpened.round().astype(np.uint8)\n",
    "    if threshold>0:\n",
    "        low_contrast_mask=np.absolute(image-blurred)<threshold\n",
    "        np.copyto(sharpened,image,where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "def clahe(image):\n",
    "    clahe=cv2.createCLAHE(clipLimit=1,tileGridSize=(2,2))\n",
    "    lab=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "    lab[:,:,0]=clahe.apply(lab[:,:,0])\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def enhance_image(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_sharpened=unsharp_mask(img)\n",
    "    image_clahe=clahe(image_sharpened)\n",
    "    image_tensor=tt.ToTensor()(image_clahe)   \n",
    "    return image_tensor\n",
    "def alpha_blending(image1, image2, alpha=0.6):\n",
    "    blended = cv2.addWeighted(image1, alpha, image2, 1 - alpha, 4)\n",
    "    return blended\n",
    "def image_addition(coeff,img_path1,img_path2):\n",
    "    img1=cv2.cvtColor(cv2.imread(img_path1),cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.cvtColor(cv2.imread(img_path2),cv2.COLOR_BGR2RGB)\n",
    "    img_f=tt.ToTensor()(alpha_blending(img1,img2))    \n",
    "    return img_f\n",
    "def save_image_final(img_tensor,file_path):\n",
    "    if img_tensor.shape[0]!=3:\n",
    "        raise ValueError(\"Input tensor must have 3 channels only...\")\n",
    "    rgb_array=img_tensor.permute(1,2,0).cpu().detach().numpy()\n",
    "    rgb_image=Image.fromarray((np.clip(rgb_array,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    rgb_image.save(file_path)\n",
    "def enhance_image_merged(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.fastNlMeansDenoisingColored(img,None,10,10,3,21)\n",
    "    image_sharpened=unsharp_mask(img2)\n",
    "    image_clahe=clahe(image_sharpened)\n",
    "    image_tensor=tt.ToTensor()(image_clahe)   \n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2dce86e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.297667Z",
     "iopub.status.busy": "2024-07-09T16:10:00.297234Z",
     "iopub.status.idle": "2024-07-09T16:10:00.311881Z",
     "shell.execute_reply": "2024-07-09T16:10:00.310521Z"
    },
    "papermill": {
     "duration": 0.02434,
     "end_time": "2024-07-09T16:10:00.314597",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.290257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_run(haze_img_path,i=0,folder_name='Inference_Results'):\n",
    "    os.makedirs(f'/kaggle/working/{folder_name}',exist_ok=True)\n",
    "    dwt_dehazenet_rgb.eval()\n",
    "    dwt_dehazenet_rgb.eval()\n",
    "    start_time=time.time()\n",
    "    haze_img_tensor=cv2.cvtColor(cv2.imread(haze_img_path),cv2.COLOR_BGR2RGB)\n",
    "    haze_img_tensor=Image.open(haze_img_path)\n",
    "    img_tensor=input_transforms_rgb(haze_img_tensor).cpu()\n",
    "    \n",
    "    model_output1=dwt_dehazenet_rgb(img_tensor.unsqueeze(0)).cpu()\n",
    "    model_output2=dehazenet_rgb(img_tensor.unsqueeze(0)).cpu()\n",
    "    \n",
    "    save_image_rgb(model_output1.squeeze(),f'/kaggle/working/{folder_name}/output_image_{i}_1.png')\n",
    "    save_image_rgb(model_output2.squeeze(),f'/kaggle/working/{folder_name}/output_image_{i}_2.png')\n",
    "    \n",
    "    proc_out_tensor1=enhance_image(f'/kaggle/working/{folder_name}/output_image_{i}_1.png')\n",
    "    proc_arr1=proc_out_tensor1.permute(1,2,0).cpu().detach().numpy()\n",
    "    proc_image1=Image.fromarray((np.clip(proc_arr1,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    proc_image1.save(f'/kaggle/working/{folder_name}/processed_image_{i}_1.png')\n",
    "    \n",
    "    proc_out_tensor2=enhance_image(f'/kaggle/working/{folder_name}/output_image_{i}_2.png')\n",
    "    proc_arr2=proc_out_tensor2.permute(1,2,0).cpu().detach().numpy()\n",
    "    proc_image2=Image.fromarray((np.clip(proc_arr2,0,1)*255).astype(np.uint8),mode='RGB')\n",
    "    proc_image2.save(f'/kaggle/working/{folder_name}/processed_image_{i}_2.png')\n",
    "    \n",
    "    blended_image=image_addition(0.6,f'/kaggle/working/{folder_name}/processed_image_{i}_2.png',\n",
    "                                 f'/kaggle/working/{folder_name}/processed_image_{i}_1.png')\n",
    "    save_image_final(blended_image.squeeze(),f'/kaggle/working/{folder_name}/merged_image_{i}.png')\n",
    "    proc_blended=enhance_image_merged(f'/kaggle/working/{folder_name}/merged_image_{i}.png')\n",
    "    save_image_final(blended_image.squeeze(),f'/kaggle/working/{folder_name}/proc_merged_image_{i}.png')\n",
    "    cnn_processed=final_cnn(tt.ToTensor()(cv2.cvtColor(cv2.imread(f'/kaggle/working/{folder_name}/proc_merged_image_{i}.png'),\n",
    "                                                       cv2.COLOR_BGR2RGB)))\n",
    "    save_image_final(cnn_processed.squeeze(),f'/kaggle/working/{folder_name}/cnn_processed_image_{i}.png')\n",
    "    print('Processed....')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b744d0d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T16:10:00.328209Z",
     "iopub.status.busy": "2024-07-09T16:10:00.327764Z",
     "iopub.status.idle": "2024-07-09T16:10:01.715442Z",
     "shell.execute_reply": "2024-07-09T16:10:01.713889Z"
    },
    "papermill": {
     "duration": 1.398261,
     "end_time": "2024-07-09T16:10:01.718794",
     "exception": false,
     "start_time": "2024-07-09T16:10:00.320533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed....\n"
     ]
    }
   ],
   "source": [
    "model_run('/kaggle/input/dehazing-dataset-thesis/NH-HAZE/NH-HAZE/01_hazy.png')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5101434,
     "sourceId": 8729607,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5239863,
     "sourceId": 8857586,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.854389,
   "end_time": "2024-07-09T16:10:03.251623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T16:09:27.397234",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
